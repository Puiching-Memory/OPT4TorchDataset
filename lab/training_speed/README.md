# 研究训练速度与缓存策略的关系

## 现象梳理

- `experiment.py` 默认使用 `RandomRGBDataset`，数据集大小约为 10 000 条样本（625 个 batch × batch size 16），仅训练 1 个 epoch。
- 缓存容量被设置为数据集规模的 30%，且采样方式为 `RandomSampler(..., replacement=True)`，因此单个 epoch 内会有约 60% 的样本首次访问、其余约 40% 为重复访问。
- 在常见模型（ResNet50、EfficientNet-B0、MobileNetV4）上，训练耗时主要来自前向、反向与优化步骤，数据加载只占很小比例。


## 为什么 OPT 没有显著提速？

1. **训练计算是主要瓶颈**：GPU 前向/反向传播的耗时远超数据读取，缓存命中后节省的几十毫秒被模型计算淹没。
2. **缓存容量受限且访问模式高度随机**：在开启放回采样的场景中，OPT 即便提前知道未来访问顺序，也难以在 30% 的缓存容量内取得很高的命中率；多数样本仍会首次从磁盘读取。
3. **OPT 装饰器存在额外的 CPU 开销**：每次访问都要执行淘汰计划查表、维护堆结构，相比简单的 `cachetools` 装饰器更重，若命中率不高，会抵消掉 IO 节省甚至拖慢整体速度。


## 建议的诊断与优化方向

- **区分数据层与计算层耗时**：在训练循环里分别计时数据加载、模型前向/反向阶段，明确瓶颈所在。
- **扩大重用场景**：提高 `epochs`、改用固定顺序（如 `SequentialSampler`）、或缩小数据集规模，增加对同一索引的重复访问频次。
- **调整缓存容量/策略**：根据显存与内存预算提高 `cache_size_ratio`，或针对热度分布更集中的工作负载再评估 OPT 的收益。